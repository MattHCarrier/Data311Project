---
title: "Project Analysis"
author: "Raphael Chevallier, Ty Kreway, Matt Carrier, Mark Meyer, Simran Tejay"
date: "3/21/2019"
output: html_document
---

```{r setup, include=FALSE}
knitr::opts_chunk$set(echo = TRUE)
```

# Cleaning the data of missing points and inconsistencies
```{r}
setwd("/Users/raphaelchevallier/Documents/DATA311/DATA311Project")
data = read.csv("Cost_of_living_index.csv", header = TRUE)
attach(data)
data
```

# Basic Visualization of the data and getting acquainted with it
```{r}
dim(data) #get the dimensiality of dataset
sapply(data, class) #get the class of the dataset
levels(data$City) #see all the different factors in the City variable
summary(data)#get the basic summary of the whole dataset
```

# First draft Random Forest with no training/testing data seperation
```{r}
set.seed(450)
library(randomForest)
cityRate1 = randomForest(Cost.of.Living.Index ~ Rank + Rent.Index + Cost.of.Living.Plus.Rent.Index + Groceries.Index + Restaurant.Price.Index + Local.Purchasing.Power.Index, data = data, importance = TRUE, ntree = 500, mtry = 2)#limit randomise variable for forest
cityRate1
importance(cityRate1)
summary(cityRate1)
prediction1 = predict(cityRate1, data)
solution1 = data.frame(City = data$City, Cost.of.Living.Index = prediction1)
solution1
```

Here we notice that the MSE of the random forest is quite low. The results of classifying the cities by cost of living is pretty accurate in many cases. Of course this is due to the fact that we are using the whole data set for both training the model and running the model.

#Random Forest Analysis with test and training to predict Cost of Living
```{r}
set.seed(450)
library(randomForest)
trainindex <- sample(1:nrow(data), 200)
train <- droplevels(data[trainindex, ])
test <- droplevels(data[-trainindex, ])
#cityRate2 = randomForest(Cost.of.Living.Index ~ Rank + Rent.Index + Cost.of.Living.Plus.Rent.Index + Groceries.Index + Restaurant.Price.Index + Local.Purchasing.Power.Index, data = train, ntree = 500, mtry = 2, importance = TRUE)#limit randomise variable for forest
cityRate2 = randomForest(Cost.of.Living.Index ~ Rank + Cost.of.Living.Plus.Rent.Index + Groceries.Index + Restaurant.Price.Index, data = train, ntree = 500, mtry = 2, importance = TRUE)#limit randomise variable for forest, shown that rent and local purchasing power were not very important at all compared to other variables
cityRate2
importance(cityRate2)
summary(cityRate2)
prediction2 = predict(cityRate2, test)
#prediction
solution2 = data.frame(City = test$City, Cost.of.Living.Index = prediction2)
solution2
```

Here we implement the idea of having two seperate datasets by splitting the data in train and test. This produces a bigger MSE and a bit less accuracy however it performs well at classifying unseen data with a cost of living and is still viable at classifying for cost of living each city. As this is a Random Forest algorithm, cross validation is unnecessary for overfitting problem due to the OOB error estimate as it is tested internally. We can also see from the commented out model that rent and local purchasing power were ineffective for the model so we decided to leave them out

# Neural Net Analysis
```{r}
library(NeuralNetTools)
library(neuralnet)
set.seed(450)
nums = unlist(lapply(data, is.numeric))  
dataNums = data[ , nums]
scar <- apply(dataNums, 2, function(v) (v-min(v))/(max(v)-min(v)))
train <- scar[trainindex, ]
test <- scar[-trainindex, ]
nn = neuralnet(Cost.of.Living.Index ~ Rank + Cost.of.Living.Plus.Rent.Index + Groceries.Index + Restaurant.Price.Index, data=train, hidden=5, linear.output = FALSE)
nn$result.matrix
plot(nn)
summary(nn)

testing <- subset(test, select = c("Rank","Cost.of.Living.Plus.Rent.Index", "Groceries.Index", "Restaurant.Price.Index"))
head(testing)
nn.results <- compute(nn, testing)
results <- data.frame(actual = test[Cost.of.Living.Index], prediction = nn.results$net.result)
results
```
